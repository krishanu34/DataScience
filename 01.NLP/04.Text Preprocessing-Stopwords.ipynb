{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishanu34/DataScience/blob/main/01.NLP/04.Text%20Preprocessing-Stopwords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "971da2a2",
      "metadata": {
        "id": "971da2a2"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishanu34/DataScience/blob/main/01.NLP/04.Text Preprocessing-Stopwords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qdhXsziReHpZ"
      },
      "id": "qdhXsziReHpZ",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad9b8815"
      },
      "source": [
        "### Stop Words in NLP\n",
        "\n",
        "Stop words are commonly used words in a language (like \"the\", \"a\", \"is\", \"in\") that are often removed during text preprocessing in NLP. These words are usually filtered out because they don't carry significant meaning and can add noise to the data, potentially affecting the performance of NLP models. Removing stop words helps to focus on the more important terms in the text, reducing the dimensionality of the data and improving the efficiency of algorithms. The list of stop words can vary depending on the specific NLP task and the language being processed."
      ],
      "id": "ad9b8815"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "20ea1d02",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "20ea1d02"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "Natural language processing (NLP) is a fascinating field at the intersection of computer science, artificial intelligence, and linguistics.\n",
        "It focuses on enabling computers to understand, interpret, and generate human language.\n",
        "This involves a wide range of tasks, including text classification, sentiment analysis, machine translation, question answering, and text summarization.\n",
        "NLP has become increasingly important in today's data-driven world, with applications in various industries such as healthcare, finance, and customer service.\n",
        "One of the fundamental steps in many NLP tasks is text preprocessing, which involves cleaning and preparing the text data for analysis.\n",
        "This often includes tasks like tokenization (breaking down text into individual words or sub-word units), stemming or lemmatization (reducing words to their root form), and removing stop words.\n",
        "Stop words are common words like \"the\", \"a\", \"is\", and \"in\" that often don't carry significant meaning and can be removed to reduce noise and improve the performance of NLP models.\n",
        "Another important aspect of NLP is feature extraction, which involves converting text data into numerical representations that can be used by machine learning algorithms.\n",
        "Common techniques include bag-of-words, TF-IDF (Term Frequency-Inverse Document Frequency), and word embeddings.\n",
        "Bag-of-words represents text as a collection of word counts, while TF-IDF assigns weights to words based on their frequency in a document and across a corpus.\n",
        "Word embeddings, such as Word2Vec and GloVe, represent words as dense vectors in a continuous vector space, capturing semantic relationships between words.\n",
        "NLP models can be broadly categorized into traditional machine learning models and deep learning models.\n",
        "Traditional models like Naive Bayes and Support Vector Machines have been used for tasks like text classification, while deep learning models,\n",
        "such as Recurrent Neural Networks (RNNs) and Transformers, have achieved state-of-the-art results in various NLP tasks, particularly in areas like machine translation and text generation.\n",
        "The field of NLP is constantly evolving, with new techniques and models being developed.\n",
        "With the increasing availability of large datasets and computational resources, NLP is expected to play an even more significant role in the future,\n",
        "enabling more natural and intuitive interactions between humans and computers.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FAne-3QbqvE",
        "outputId": "4fb4c2ce-baec-4bcf-e40f-df4f31914310"
      },
      "id": "_FAne-3QbqvE",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('english')"
      ],
      "metadata": {
        "id": "pRWAXMxxeaFs",
        "outputId": "62e64b85-d8f4-4c7e-c060-90a6024a0414",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pRWAXMxxeaFs",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he'd\",\n",
              " \"he'll\",\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " \"he's\",\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " 'if',\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " \"i've\",\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she'd\",\n",
              " \"she'll\",\n",
              " \"she's\",\n",
              " 'should',\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " \"should've\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " \"we've\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " 'your',\n",
              " \"you're\",\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " \"you've\"]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "sentences = nltk.sent_tokenize(text)"
      ],
      "metadata": {
        "id": "kaHIVr4Ee5Bb"
      },
      "id": "kaHIVr4Ee5Bb",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply Stopwords and filter And then apply Stemming"
      ],
      "metadata": {
        "id": "28Lc4PLIflue"
      },
      "id": "28Lc4PLIflue"
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentences)):\n",
        "  words = nltk.word_tokenize(sentences[i])\n",
        "  words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "  sentences[i] = ' '.join(words)\n",
        "sentences"
      ],
      "metadata": {
        "id": "ftXtWriNfW6s",
        "outputId": "e18fb74c-6fb1-4795-d831-0ded0cb9d8c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ftXtWriNfW6s",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['natur languag process ( nlp ) fascin field intersect comput scienc , artifici intellig , linguist .',\n",
              " 'it focus enabl comput understand , interpret , gener human languag .',\n",
              " 'thi involv wide rang task , includ text classif , sentiment analysi , machin translat , question answer , text summar .',\n",
              " \"nlp becom increasingli import today 's data-driven world , applic variou industri healthcar , financ , custom servic .\",\n",
              " 'one fundament step mani nlp task text preprocess , involv clean prepar text data analysi .',\n",
              " 'thi often includ task like token ( break text individu word sub-word unit ) , stem lemmat ( reduc word root form ) , remov stop word .',\n",
              " \"stop word common word like `` '' , `` '' , `` '' , `` '' often n't carri signific mean remov reduc nois improv perform nlp model .\",\n",
              " 'anoth import aspect nlp featur extract , involv convert text data numer represent use machin learn algorithm .',\n",
              " 'common techniqu includ bag-of-word , tf-idf ( term frequency-invers document frequenc ) , word embed .',\n",
              " 'bag-of-word repres text collect word count , tf-idf assign weight word base frequenc document across corpu .',\n",
              " 'word embed , word2vec glove , repres word dens vector continu vector space , captur semant relationship word .',\n",
              " 'nlp model broadli categor tradit machin learn model deep learn model .',\n",
              " 'tradit model like naiv bay support vector machin use task like text classif , deep learn model , recurr neural network ( rnn ) transform , achiev state-of-the-art result variou nlp task , particularli area like machin translat text gener .',\n",
              " 'the field nlp constantli evolv , new techniqu model develop .',\n",
              " 'with increas avail larg dataset comput resourc , nlp expect play even signific role futur , enabl natur intuit interact human comput .']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply Stopwords and filter And then apply Lemitization"
      ],
      "metadata": {
        "id": "eF05mTAegoEd"
      },
      "id": "eF05mTAegoEd"
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "K36Pd133gFUl"
      },
      "id": "K36Pd133gFUl",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = nltk.sent_tokenize(text)"
      ],
      "metadata": {
        "id": "FFkegrvLg7js"
      },
      "id": "FFkegrvLg7js",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentences)):\n",
        "  words = nltk.word_tokenize(sentences[i])\n",
        "  words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "  sentences[i] = ' '.join(words)\n",
        "sentences"
      ],
      "metadata": {
        "id": "PGoi_kr8guI8",
        "outputId": "d42c86ff-b0c9-421b-8d9d-9766b9977b01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PGoi_kr8guI8",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural language processing ( NLP ) fascinating field intersection computer science , artificial intelligence , linguistics .',\n",
              " 'It focus enabling computer understand , interpret , generate human language .',\n",
              " 'This involves wide range task , including text classification , sentiment analysis , machine translation , question answering , text summarization .',\n",
              " \"NLP become increasingly important today 's data-driven world , application various industry healthcare , finance , customer service .\",\n",
              " 'One fundamental step many NLP task text preprocessing , involves cleaning preparing text data analysis .',\n",
              " 'This often includes task like tokenization ( breaking text individual word sub-word unit ) , stemming lemmatization ( reducing word root form ) , removing stop word .',\n",
              " \"Stop word common word like `` '' , `` '' , `` '' , `` '' often n't carry significant meaning removed reduce noise improve performance NLP model .\",\n",
              " 'Another important aspect NLP feature extraction , involves converting text data numerical representation used machine learning algorithm .',\n",
              " 'Common technique include bag-of-words , TF-IDF ( Term Frequency-Inverse Document Frequency ) , word embeddings .',\n",
              " 'Bag-of-words represents text collection word count , TF-IDF assigns weight word based frequency document across corpus .',\n",
              " 'Word embeddings , Word2Vec GloVe , represent word dense vector continuous vector space , capturing semantic relationship word .',\n",
              " 'NLP model broadly categorized traditional machine learning model deep learning model .',\n",
              " 'Traditional model like Naive Bayes Support Vector Machines used task like text classification , deep learning model , Recurrent Neural Networks ( RNNs ) Transformers , achieved state-of-the-art result various NLP task , particularly area like machine translation text generation .',\n",
              " 'The field NLP constantly evolving , new technique model developed .',\n",
              " 'With increasing availability large datasets computational resource , NLP expected play even significant role future , enabling natural intuitive interaction human computer .']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-0nwYdLFg2Pj"
      },
      "id": "-0nwYdLFg2Pj",
      "execution_count": 22,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}